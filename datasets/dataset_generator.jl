#= Script to generate the in-silico training set for the test-case.
The observation dataset are generated by solving the ODE system with the ground-truth parameters and initial conditions.
The training set is generated by adding noise to the observation dataset, with the noise magnitude defined by the max-min variation of the timeseries (error-levels: 0% and 5%)
=# 

cd(@__DIR__)

using ComponentArrays, Serialization, DifferentialEquations, LinearAlgebra, Random, DataFrames, CSV, Statistics, Printf
using StableRNGs

noise_magnitudes = [0.0, 0.05]

column_names = []
problems = ["lotka_volterra", "glycolysis", "cell_apoptosis"]
rng = Random.default_rng()

include("non_perturbed_dataset_generator.jl")

#generates the data for different test cases and different problems
for noise_magnitude in noise_magnitudes

  #set the seed for reprodubibility
  Random.seed!(rng, 1)

  for problem in problems

    println("Analyzing problem "*problem*" with noise level "* string(noise_magnitude) *"...")
    
    #sets the specific problem settings
    if problem == "cell_apoptosis"

      #includes the specific model functions
      include("../test_case_settings/cell_apoptosis_settings/cell_apop_model_functions.jl")
      include("../test_case_settings/cell_apoptosis_settings/cell_apop_model_settings.jl")

      column_names = ["t", "s1", "s2", "s3", "s4", "s5", "s6", "s7", "s8"]

      integrator = Rosenbrock23(autodiff=false)
    elseif problem == "glycolysis"

      include("../test_case_settings/glyc_model_settings/glycolitic_model_functions.jl")
      include("../test_case_settings/glyc_model_settings/glycolitic_model_settings.jl")

      column_names = ["t", "s1", "s2", "s3", "s4", "s5", "s6", "s7"]

      integrator = Vern7()
    elseif problem == "lotka_volterra"

      include("../test_case_settings/lv_model_settings/lotka_volterra_model_functions.jl")
      include("../test_case_settings/lv_model_settings/lotka_volterra_model_settings.jl")

      column_names = ["t", "s1", "s2"]

      integrator = Vern7()
    end

    #settings for the training set sampling
    tspan = (initial_time_training, end_time_training)
    tsteps = range(tspan[1], tspan[2], length=21)
    stepsize = (tspan[2] - tspan[1]) / (21 - 1)
    lentgth_tsteps = length(tsteps)

    #generates non perturbed training set given the derivative function and the stepsize
    extended_tspan = (tspan[1], 2*tspan[2])
    extended_tsteps = range(extended_tspan[1], extended_tspan[2], 1000)
    pure_solution_dataframe = generate_non_perturbed_training_set(ground_truth_function, original_u0, original_parameters, extended_tspan, extended_tsteps; column_names=column_names, integrator=integrator)

    solution_dataframe = generate_non_perturbed_training_set(ground_truth_function, original_u0, original_parameters, tspan, tsteps; column_names=column_names, integrator=integrator)
    solution_matrix = Array(solution_dataframe[:, :])

    ode_data_pure = transpose(solution_matrix[:, 2:end])
    x̄ = mean(ode_data_pure, dims=2)
    max_variation = maximum(ode_data_pure, dims=2) - minimum(ode_data_pure, dims=2)
    #noise_magnitude = 0.0
    #ode_data = max.(ode_data_pure .+ (noise_magnitude * x̄) .* randn(rng, eltype(ode_data_pure), size(ode_data_pure)), 0.0)
    ode_data = max.(ode_data_pure .+ (noise_magnitude * max_variation) .* randn(rng, eltype(ode_data_pure), size(ode_data_pure)), 0.0)
    #ode_data = max.(ode_data_pure .+ noise_magnitude .* ode_data_pure .* randn(rng, eltype(ode_data_pure), size(ode_data_pure)), 0.0)
    #ode_data_std = reshape(repeat(noise_magnitude * x̄, outer=21), size(ode_data)) 
    ode_data_std = reshape(repeat(noise_magnitude * max_variation, outer=21), size(ode_data)) 

    perturbed_dataframe = DataFrame(transpose(ode_data), names(solution_dataframe)[2:end])
    perturbed_dataframe[!, :t] = tsteps
    perturbed_dataframe = perturbed_dataframe[:, [end; 1:end-1]]

    perturbed_dataframe_sd = DataFrame(transpose(ode_data_std), names(solution_dataframe)[2:end])
    perturbed_dataframe_sd[!, :t] = tsteps
    #reorder the columns with t as first
    perturbed_dataframe_sd = perturbed_dataframe_sd[:, [end; 1:end-1]]

    folder_name = "e"*string(noise_magnitude)*"/"
    if !isdir(folder_name)
      mkdir(folder_name)
    end

    data_folder_name = folder_name*"data/"
    if !isdir(data_folder_name)
      mkdir(data_folder_name)
    end

    #save both in DF and array format
    serialize("./"*data_folder_name*"/"*"ode_data_" * problem * ".jld", ode_data)
    serialize("./"*data_folder_name*"/"*"ode_data_std_" * problem * ".jld", ode_data_std)
    serialize("./"*data_folder_name*"/"*"pert_df_" * problem * ".jld", perturbed_dataframe)
    serialize("./"*data_folder_name*"/"*"pert_df_sd_" * problem * ".jld", perturbed_dataframe_sd)
  end
end

